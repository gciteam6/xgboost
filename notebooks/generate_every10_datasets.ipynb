{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path, pardir\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT_DIRPATH = path.join(os.getcwd(), pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(PROJECT_ROOT_DIRPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.forecast import ForecastHandler\n",
    "from src.features.dataset import DatasetHandler\n",
    "from src.features.dummy import DummyFeatureHandler\n",
    "from src.features.time_series import TimeSeriesReshaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KWARGS_READ_CSV = {\n",
    "    \"sep\": \"\\t\",\n",
    "    \"header\": 0,\n",
    "    \"parse_dates\": [0],\n",
    "    \"index_col\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIME_NAME = \"kwh\"\n",
    "CIRCULAR_CATEGORICAL_VARIABLES = (\"wv\",)\n",
    "additional_removal_columns = [\"we\",]\n",
    "datetime_fmt = \"(?P<year>\\d{4})(?P<month>\\d{1,2})(?P<day>\\d{1,2})(?P<hour>\\d{2})(?P<minute>\\d{2})\"\n",
    "LOCATIONS = (\n",
    "    \"ukishima\",\n",
    "    \"ougishima\",\n",
    "    \"yonekurayama\",\n",
    ")\n",
    "loc_field_dict = {\n",
    "    \"ukishima\": \"SOLA01\",\n",
    "    \"ougishima\": \"SOLA02\",\n",
    "    \"yonekurayama\": \"SOLA03\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = ForecastHandler()\n",
    "maker = DatasetHandler(columns_y=[OBJECTIME_NAME, ])\n",
    "categ = DummyFeatureHandler()\n",
    "reshaper = TimeSeriesReshaper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectives_filepath = path.join(maker.RAW_DATA_BASEPATH, \"train_kwh.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_X_y(location):\n",
    "    df_forecast = forecast.read_tsv(forecast.gen_filepath(location))\n",
    "    df_forecast_expanded = forecast.add_datetime_ticks(df_forecast)\n",
    "\n",
    "    whole_day_data_name_list = forecast.get_whole_day_data_columns(df_forecast.columns)\n",
    "\n",
    "    for whole_day_data_name in whole_day_data_name_list:\n",
    "        sr_expand_whole_day_data = \\\n",
    "            forecast.expand_whole_day_data(df_forecast[whole_day_data_name])\n",
    "        df_forecast_expanded.loc[\n",
    "            sr_expand_whole_day_data.index,\n",
    "            whole_day_data_name\n",
    "        ] = sr_expand_whole_day_data\n",
    "\n",
    "    time_ranged_data_name_list = \\\n",
    "        forecast.get_time_ranged_data_columns(df_forecast.columns)\n",
    "\n",
    "    for time_ranged_data_name in time_ranged_data_name_list:\n",
    "        sr_expand_time_ranged_data = \\\n",
    "            forecast.expand_time_ranged_data(df_forecast[time_ranged_data_name])\n",
    "        df_forecast_expanded.loc[\n",
    "            sr_expand_time_ranged_data.index,\n",
    "            forecast.extract_attribute_from_time_ranged_column_name(time_ranged_data_name)\n",
    "        ] = sr_expand_time_ranged_data\n",
    "\n",
    "    df_forecast_expanded.drop(time_ranged_data_name_list, axis=1, inplace=True)\n",
    "\n",
    "    df_weather = pd.get_dummies(df_forecast_expanded[\"we\"], prefix=\"we\")\n",
    "    df_forecast_expanded = df_forecast_expanded.merge(df_weather, **maker.KWARGS_OUTER_MERGE)\n",
    "\n",
    "    df_month = categ.extract_month(df_forecast_expanded.index)\n",
    "    df_month = pd.get_dummies(df_month, prefix=\"month\")\n",
    "    df_forecast_expanded = df_forecast_expanded.merge(df_month, **maker.KWARGS_OUTER_MERGE)\n",
    "\n",
    "    df_hour = categ.extract_hour(df_forecast_expanded.index)\n",
    "    df_hour = pd.get_dummies(df_hour, prefix=\"hour\")\n",
    "    df_forecast_expanded = df_forecast_expanded.merge(df_hour, **maker.KWARGS_OUTER_MERGE)\n",
    "\n",
    "    for col_name, correspond_dict in categ.FORECAST_ATTRIBUTES.items():\n",
    "        df_forecast_expanded[col_name] = categ.convert_series_along_dict(df_forecast_expanded[col_name], correspond_dict)\n",
    "\n",
    "    for col_name in CIRCULAR_CATEGORICAL_VARIABLES:\n",
    "        df_temp_cos_sin = categ.convert_linear_to_circular(\n",
    "            df_forecast_expanded[col_name], len(categ.FORECAST_ATTRIBUTES[col_name])\n",
    "        )\n",
    "        df_forecast_expanded = df_forecast_expanded.merge(\n",
    "            df_temp_cos_sin, **maker.KWARGS_OUTER_MERGE\n",
    "        )\n",
    "        df_forecast_expanded.drop(col_name, axis=1, inplace=True)\n",
    "\n",
    "    df_forecast_expanded[\"past_time\"] = pd.Series(np.arange(df_forecast_expanded.shape[0]),\n",
    "                                                  index=df_forecast_expanded.index,\n",
    "                                                  name=\"past_time\")\n",
    "\n",
    "    drop_col_name_list = reshaper.DROP_LABEL_NAMES + additional_removal_columns\n",
    "    df_forecast_expanded.drop(drop_col_name_list, axis=1, inplace=True)\n",
    "\n",
    "    df_kwh = pd.read_csv(objectives_filepath, sep=\"\\t\", index_col=[0])\n",
    "    df_kwh.index = pd.to_datetime(\n",
    "        pd.Series(df_kwh.index).apply(str).str.extract(datetime_fmt, expand=False)\n",
    "    )\n",
    "    df_y = df_kwh[loc_field_dict[location]].to_frame()\n",
    "    df_y.rename(columns=lambda x: OBJECTIME_NAME, inplace=True)\n",
    "\n",
    "    df_X_y = df_forecast_expanded.merge(df_y, **maker.KWARGS_OUTER_MERGE)\n",
    "\n",
    "    df_train, df_test = maker.separate_train_test(df_X_y)\n",
    "    df_test, _ = maker.separate_X_y(df_test)\n",
    "    \n",
    "    df_X_y.to_csv(\n",
    "        path.join(maker.PROCESSED_DATA_BASEPATH, \"dataset.train_X_y.every_10.{l}.tsv\".format(l=location)),\n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "    df_test.to_csv(\n",
    "        path.join(maker.PROCESSED_DATA_BASEPATH, \"dataset.test_X.every_10.{l}.tsv\".format(l=location)),\n",
    "        sep=\"\\t\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実働部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in LOCATIONS:\n",
    "    get_train_test_X_y(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
